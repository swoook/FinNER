{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebb6181-67e7-471b-820b-f90dadc87cf9",
   "metadata": {},
   "source": [
    "# Pre-trained NER models for Korean corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2c2bd-7a11-4863-be1b-1be17e5d14de",
   "metadata": {},
   "source": [
    "## monologg/KoELECTRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64484bc-e714-4f86-87dc-8bf1c56a1524",
   "metadata": {},
   "source": [
    "### [monologg/koelectra-small-finetuned-naver-ner](https://huggingface.co/monologg/koelectra-small-finetuned-naver-ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b6195-f7a8-4396-a087-0c8768f89c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/monologg/KoELECTRA-Pipeline KoelectraPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e62e9d5-31ea-469e-b043-85ef20fdfd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ElectraTokenizer, ElectraForTokenClassification\n",
    "from KoelectraPipeline.ner_pipeline import NerPipeline\n",
    "from pprint import pprint\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device_no = 0 if torch.cuda.is_available() else -1\n",
    "query = \"현대자동차가 사우디아라비아에 반조립(CKD) 공장 설립을 검토한다. 현대차(005380)의 첫 중동 생산기지로 사우디가 확정되면 성장 가능성이 큰 현지 시장 공략에도 속도가 붙을 것으로 전망된다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf4c779-6955-4f5f-85c3-82fe3a9f2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-small-finetuned-naver-ner\")\n",
    "model = ElectraForTokenClassification.from_pretrained(\"monologg/koelectra-small-finetuned-naver-ner\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fafc9-dc48-4770-a5a7-db24be5b0176",
   "metadata": {},
   "source": [
    "- It seems `NerPipeline` is not available in `transformers` latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1beb7cf-ae49-4779-9038-e7ab94c67d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = NerPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ignore_labels=[],\n",
    "    ignore_special_tokens=True,\n",
    "    device=device_no\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f2d64-319f-4551-badd-33f232c96b27",
   "metadata": {},
   "source": [
    "- Showing how the NER pipeline works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196586c4-a1c4-46a2-a5ec-3db2982ce85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'ORG-B', 'score': 0.9996711611747742, 'word': '현대자동차가'},\n",
      " {'entity': 'LOC-B', 'score': 0.9993993639945984, 'word': '사우디아라비아에'},\n",
      " {'entity': 'TRM-B', 'score': 0.9200928807258606, 'word': '반조립(CKD)'},\n",
      " {'entity': 'O', 'score': 0.9994731545448303, 'word': '공장'},\n",
      " {'entity': 'O', 'score': 0.99997478723526, 'word': '설립을'},\n",
      " {'entity': 'O', 'score': 0.9999741911888123, 'word': '검토한다.'},\n",
      " {'entity': 'ORG-B', 'score': 0.999255895614624, 'word': '현대차(005380)의'},\n",
      " {'entity': 'NUM-B', 'score': 0.9716644287109375, 'word': '첫'},\n",
      " {'entity': 'LOC-B', 'score': 0.6237317323684692, 'word': '중동'},\n",
      " {'entity': 'O', 'score': 0.9186286330223083, 'word': '생산기지로'},\n",
      " {'entity': 'LOC-B', 'score': 0.9993852972984314, 'word': '사우디가'},\n",
      " {'entity': 'O', 'score': 0.9999492764472961, 'word': '확정되면'},\n",
      " {'entity': 'O', 'score': 0.9999668598175049, 'word': '성장'},\n",
      " {'entity': 'O', 'score': 0.9999701976776123, 'word': '가능성이'},\n",
      " {'entity': 'O', 'score': 0.9999551773071289, 'word': '큰'},\n",
      " {'entity': 'O', 'score': 0.9998905062675476, 'word': '현지'},\n",
      " {'entity': 'O', 'score': 0.9999563694000244, 'word': '시장'},\n",
      " {'entity': 'O', 'score': 0.9999776482582092, 'word': '공략에도'},\n",
      " {'entity': 'O', 'score': 0.9999712109565735, 'word': '속도가'},\n",
      " {'entity': 'O', 'score': 0.9999760389328003, 'word': '붙을'},\n",
      " {'entity': 'O', 'score': 0.9999691247940063, 'word': '것으로'},\n",
      " {'entity': 'O', 'score': 0.9999678730964661, 'word': '전망된다.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(ner(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5015631-5e88-4ca8-8a47-8876913b442d",
   "metadata": {},
   "source": [
    "- Elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175b97a9-0a7a-4918-bb62-7b0f5d74751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 21.58198356628418 ms\n"
     ]
    }
   ],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "ner(query)\n",
    "end.record()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print('Elapsed time: {} ms'.format(start.elapsed_time(end)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11486901-106d-4331-91f1-468e76079aed",
   "metadata": {},
   "source": [
    "### [monologg/koelectra-base-v3-naver-ner](https://huggingface.co/monologg/koelectra-base-v3-naver-ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f0385f-3e38-44bc-9d25-6943d0427874",
   "metadata": {},
   "source": [
    "- `transformers==3.3.1` can't find `monologg/koelectra-base-v3-naver-ner`\n",
    "\n",
    "```\n",
    "OSError: Model name 'monologg/koelectra-base-v3-naver-ner' was not found in tokenizers model name list (google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). We assumed 'monologg/koelectra-base-v3-naver-ner' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.txt'] but couldn't find such vocabulary files at this path or url.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a929087a-97a4-4054-9915-37855bae678a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Model name 'monologg/koelectra-base-v3-naver-ner' was not found in tokenizers model name list (google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). We assumed 'monologg/koelectra-base-v3-naver-ner' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.txt'] but couldn't find such vocabulary files at this path or url.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3053/3673902667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElectraTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"monologg/koelectra-base-v3-naver-ner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElectraForTokenClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"monologg/koelectra-base-v3-naver-ner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \"\"\"\n\u001b[0;32m-> 1428\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1532\u001b[0m                     \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m                     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_files_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m                 )\n\u001b[1;32m   1536\u001b[0m             )\n",
      "\u001b[0;31mOSError\u001b[0m: Model name 'monologg/koelectra-base-v3-naver-ner' was not found in tokenizers model name list (google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). We assumed 'monologg/koelectra-base-v3-naver-ner' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.txt'] but couldn't find such vocabulary files at this path or url."
     ]
    }
   ],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-naver-ner\")\n",
    "model = ElectraForTokenClassification.from_pretrained(\"monologg/koelectra-base-v3-naver-ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b1ccf-c6df-44ea-8c4a-9368f360bf60",
   "metadata": {},
   "source": [
    "```\n",
    "$ curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "$ apt-get install git-lfs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36931b-541c-4fe2-8e2c-c782c70e43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/monologg/koelectra-base-v3-naver-ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6191debd-dc53-42e5-99a5-b0dd24b80ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(\"koelectra-base-v3-naver-ner\")\n",
    "model = ElectraForTokenClassification.from_pretrained(\"koelectra-base-v3-naver-ner\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaf10eeb-699c-4afc-a817-e14ef480cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = NerPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ignore_labels=[],\n",
    "    ignore_special_tokens=True,\n",
    "    device=device_no\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcc1686-3e91-4ae2-b125-89321402e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'ORG-B', 'score': 0.9999872446060181, 'word': '현대자동차가'},\n",
      " {'entity': 'LOC-B', 'score': 0.9999710321426392, 'word': '사우디아라비아에'},\n",
      " {'entity': 'TRM-B', 'score': 0.9998471140861511, 'word': '반조립(CKD)'},\n",
      " {'entity': 'O', 'score': 0.9999819397926331, 'word': '공장'},\n",
      " {'entity': 'O', 'score': 0.9999977946281433, 'word': '설립을'},\n",
      " {'entity': 'O', 'score': 0.9999947547912598, 'word': '검토한다.'},\n",
      " {'entity': 'ORG-B', 'score': 0.9999806880950928, 'word': '현대차(005380)의'},\n",
      " {'entity': 'NUM-B', 'score': 0.9999110698699951, 'word': '첫'},\n",
      " {'entity': 'LOC-B', 'score': 0.9978455901145935, 'word': '중동'},\n",
      " {'entity': 'O', 'score': 0.9986305236816406, 'word': '생산기지로'},\n",
      " {'entity': 'LOC-B', 'score': 0.999977707862854, 'word': '사우디가'},\n",
      " {'entity': 'O', 'score': 0.9999973773956299, 'word': '확정되면'},\n",
      " {'entity': 'O', 'score': 0.9999985694885254, 'word': '성장'},\n",
      " {'entity': 'O', 'score': 0.9999983906745911, 'word': '가능성이'},\n",
      " {'entity': 'O', 'score': 0.9999987483024597, 'word': '큰'},\n",
      " {'entity': 'O', 'score': 0.9999983310699463, 'word': '현지'},\n",
      " {'entity': 'O', 'score': 0.9999986290931702, 'word': '시장'},\n",
      " {'entity': 'O', 'score': 0.9999988079071045, 'word': '공략에도'},\n",
      " {'entity': 'O', 'score': 0.9999979138374329, 'word': '속도가'},\n",
      " {'entity': 'O', 'score': 0.9999985694885254, 'word': '붙을'},\n",
      " {'entity': 'O', 'score': 0.9999980926513672, 'word': '것으로'},\n",
      " {'entity': 'O', 'score': 0.9999986886978149, 'word': '전망된다.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(ner(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f48ccc66-5535-402b-8ca6-457d1cc05cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 23.280223846435547 ms\n"
     ]
    }
   ],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "ner(query)\n",
    "end.record()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print('Elapsed time: {} ms'.format(start.elapsed_time(end)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
